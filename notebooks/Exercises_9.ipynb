{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises 9\n",
    "This notebook contains exercises for the nineth meeting.\n",
    "These exercises are about plotting data.\n",
    "\n",
    "For these exercises we will use Python libraries that might not be installed in the default Anaconda installation. \n",
    "Run the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /root/programs/miniconda3\n",
      "\n",
      "  added / updated specs: \n",
      "    - opencv\n",
      "    - scikit-image\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "    opencv:       3.3.1-py36h61133dd_2 \n",
      "    scikit-image: 0.13.1-py36h14c3975_1\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install opencv scikit-image -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 9.1 Following a reaction\n",
    "In this exercise we will try to following the progression of a reaction by looking at its color.\n",
    "The video we will use are downloaded from [Youtube](https://www.youtube.com/watch?v=Eg64S0DhAaI).\n",
    "The video-file is located in \"data/reaction.mp4\".\n",
    "It is much easier to work with image files rather than video files.\n",
    "The first thing we will do is to extract all the frames of the video into seperate files.\n",
    "The below code can do the trick ([source](https://stackoverflow.com/questions/33311153/python-extracting-and-saving-video-frames?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "save_folder = \"FOLDER_FOR_SAVEING_IMAGES\"\n",
    "vidcap = cv2.VideoCapture('PATH_TO_VIDEO')\n",
    "success,image = vidcap.read()\n",
    "count = 0\n",
    "success = True\n",
    "while success:\n",
    "    cv2.imwrite(save_folder+\"/frame%d.png\" % count, image)\n",
    "    success,image = vidcap.read()\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try to load \"frame410.png\" into Python.**\n",
    "\n",
    "- Hint: import skimage.io\n",
    "- Hint: skimage.io.imread(path_to_image)\n",
    "\n",
    "**Try to show the image.**\n",
    "\n",
    "- Hint: plt.imshow(image)\n",
    "\n",
    "**Try type np.shape(image)**\n",
    "\n",
    "You will see that the image have three dimension.\n",
    "The first two dimensions is the sides of the image, and the last dimension is the color dimension.\n",
    "The color dimension have a size of three because the colors are represented in RBG code (Red, Blue and Green).\n",
    "\n",
    "We know that reaction only happens inside the beaker, the rest of the image is therefore not of interest.\n",
    "\n",
    "**Use NumPy array slicing to choose a part of the image that only shows where the reaction happens.**\n",
    "\n",
    "- Hint: cut_image = image[x_start:x_end, y_start:y_end,:]\n",
    "\n",
    "**Try to show the cutted image.**\n",
    "\n",
    "We will now loop over all the relevant images, and try to extract how the color evolves over time. \n",
    "\n",
    "**Make a loop from image 366 to image 900 and print the average redness, blueness and greenness (remember to cut the images to only get the relevant part).**\n",
    "\n",
    "- Hint: The redness can be found by image[:, :, 0]. \":\" indicates we take all elements in the first and second dimension. \"0\" gives us the redness because we know the colors are stored as RBG.\n",
    "- Hint: np.mean(array) gives the average value of an array.\n",
    "- Hint for hint: Think of image[:, :, 0] as an array.\n",
    "\n",
    "**Make a loop from image 366 to image 900 and store the average redness, blueness and greenness in a new array.**\n",
    "\n",
    "**Make a plot of the average redness, blueness and greenness over time (time and frame number are proportional).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 9.2 Counting particles\n",
    "We will look at a picture of nano-particles ([source](http://news.mit.edu/2012/hybrid-copper-gold-nanoparticles-convert-co2)).\n",
    "This exercise is based on a [Scikit-image example](http://scikit-image.org/docs/dev/auto_examples/segmentation/plot_label.html). The image we will analyse is located in \"data/particles.jpg\".\n",
    "\n",
    "**Start by loding in the image.**\n",
    "\n",
    "- Hint: import skimage.io\n",
    "- Hint: skimage.io.imread(path_to_image)\n",
    "\n",
    "**Try to show the image.**\n",
    "\n",
    "- Hint: plt.imshow(image)\n",
    "\n",
    "If you do np.shape(image) you will see that it is of three dimensions.\n",
    "The last dimension have a size of three. \n",
    "The last dimension is RBG color values (Redness, Blueness, Greenness).\n",
    "For this exercise we only need to work on one of the color dimensions for simplicity sake.\n",
    "\n",
    "**Take out one of the color dimensions from your image.**\n",
    "\n",
    "- Hint: Use numpy array slicing. image = image[:,:,0]. This means that we take all the values in the first and second dimension, and only the zeroth value in the thrid dimension (the redness).\n",
    "\n",
    "**Try to show the image again.**\n",
    "\n",
    "In the bottom of the image there is a label that tells the scale of the image.\n",
    "When doing the image analysis, we don't want to consider this label.\n",
    "\n",
    "**Use numpy slicing to get the top part of the image, without the 20 nm label.**\n",
    "\n",
    "**Try to show the image again to be sure you got the right part.**\n",
    "\n",
    "Scikit-image have alot of function we can use.\n",
    "To distinguish the background from the particles we will use the [Otsu algorithm](https://en.wikipedia.org/wiki/Otsu%27s_method).\n",
    "We will use the version already implemented in Scikit-image.\n",
    "It can be imported by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import threshold_otsu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now get a threshold value by using this function.**\n",
    "\n",
    "- Hint: thresh = threshold_otsu(image)\n",
    "\n",
    "We can now use this threshold to make a new image array of False / True. \n",
    "In this array False indicates background and True indicates particle.\n",
    "For this we can use the closing() method from Scikit-Image.\n",
    "It can be imported by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import closing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make a True / False array (image) by using closing().**\n",
    "\n",
    "- Hint: new_image = closing(image < threshold)\n",
    "- Note: Sometimes \"<\" should be \">\" due to how the Otsu algorithm picks the threshold.\n",
    "\n",
    "**Try show the image.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Scikit-image to calculate alot of properties for us.\n",
    "First we need to transform our False/True image to a Sckikit-image label object.\n",
    "For this we need to import the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert the image to a Scikit-image label object.**\n",
    "\n",
    "- Hint: label_image = label(image)\n",
    "\n",
    "This label object can be turned into regions with associated properties by Scikit-image.\n",
    "Now import:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import regionprops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert the image to regions.**\n",
    "\n",
    "- Hint: image_regions = regionprops(label_image)\n",
    "\n",
    "Every region in image_regions have a list of properties associated with it. \n",
    "A couple of examples are:\n",
    "\n",
    "- region.area, gives the area of a region.\n",
    "- region.centroid, gives the center of a region.\n",
    "\n",
    "**Loop over the regions and count how many particles have an area larger than 60 (the unit is pixels^2).**\n",
    "\n",
    "- Hint: You can loop over the regions by: \"for region in image_regions:\"\n",
    "\n",
    "It can useful to vizually inspect that we count the particles that we expect.\n",
    "\n",
    "**Loop over the regions again and plot a circle on top of all the particles with an area larger than 60.**\n",
    "\n",
    "- Hint: Use region.centroid to get the center of the particles.\n",
    "- Hint: First, plt.imshow(image).\n",
    "- Hint: Secound, plt.plot(X, Y, 'ro', mfc='none'). The mfc='none' makes the plotted circles without filling.\n",
    "\n",
    "**Loop over the regions collect the areas and make a histogram of the found areas.**\n",
    "\n",
    "- Hint: plt.hist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
